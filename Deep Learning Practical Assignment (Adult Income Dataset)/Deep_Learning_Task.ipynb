{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ§  Deep Learning Practical Assignment (Adult Income Dataset)\n",
        "\n",
        "## ðŸ“Œ Dataset\n",
        "We will use the **Adult Income dataset** (also known as the Census Income dataset).  \n",
        "The task is to predict whether a person earns **more than $50K/year** based on demographic and employment attributes.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "THxjKfmyG-St"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETxUv-9oGeuT",
        "outputId": "74c2e005-5922-49c8-f86d-896c2130c231"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age  workclass  fnlwgt     education  education-num      marital-status  \\\n",
            "0   25    Private  226802          11th              7       Never-married   \n",
            "1   38    Private   89814       HS-grad              9  Married-civ-spouse   \n",
            "2   28  Local-gov  336951    Assoc-acdm             12  Married-civ-spouse   \n",
            "3   44    Private  160323  Some-college             10  Married-civ-spouse   \n",
            "4   18        NaN  103497  Some-college             10       Never-married   \n",
            "\n",
            "          occupation relationship   race     sex  capital-gain  capital-loss  \\\n",
            "0  Machine-op-inspct    Own-child  Black    Male             0             0   \n",
            "1    Farming-fishing      Husband  White    Male             0             0   \n",
            "2    Protective-serv      Husband  White    Male             0             0   \n",
            "3  Machine-op-inspct      Husband  Black    Male          7688             0   \n",
            "4                NaN    Own-child  White  Female             0             0   \n",
            "\n",
            "   hours-per-week native-country  class  \n",
            "0              40  United-States  <=50K  \n",
            "1              50  United-States  <=50K  \n",
            "2              40  United-States   >50K  \n",
            "3              40  United-States   >50K  \n",
            "4              30  United-States  <=50K  \n",
            "(48842, 15)\n"
          ]
        }
      ],
      "source": [
        "# Option 1: Using OpenML via scikit-learn\n",
        "from sklearn.datasets import fetch_openml\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset from OpenML\n",
        "adult = fetch_openml(name=\"adult\", version=2, as_frame=True)\n",
        "df = adult.frame\n",
        "\n",
        "print(df.head())\n",
        "print(df.shape)  # (48842, 15)\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(columns=\"class\")\n",
        "y = df[\"class\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 0: Data Preparation\n",
        "1. Load the dataset into a DataFrame.\n",
        "2. Split the data into **training, validation, and test sets**.  \n",
        "   - Suggested: 70% training, 15% validation, 15% test.\n",
        "3. Apply any necessary preprocessing:\n",
        "   - Handle categorical features (encoding).\n",
        "   - Scale numerical features if needed.\n",
        "4. After training your models, always report results on:\n",
        "   - **Training accuracy**\n",
        "   - **Validation accuracy**\n",
        "   - **Test accuracy**\n",
        "5. At the end of the assignment, **compare all methods** across train, validation, and test sets.\n"
      ],
      "metadata": {
        "id": "qqY4sTfrHQF_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3uG3mAu5HTJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Part 1: Optimizers\n",
        "1. Train the same neural network using:\n",
        "   - Stochastic Gradient Descent (SGD)\n",
        "   - SGD with Momentum\n",
        "   - Adam\n",
        "2. Compare the training and validation accuracy for each optimizer.\n",
        "3. Which optimizer converges the fastest? Which gives the best generalization?\n",
        "4. Explain *why* Adam often performs better than plain SGD.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "LPpltt4ZG3fN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wnoISz2rHMJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Batch Size\n",
        "1. Train the same model with different batch sizes (e.g., 1, 32, 128, 1024).\n",
        "2. Compare:\n",
        "   - Training speed\n",
        "   - Validation accuracy\n",
        "   - Test accuracy\n",
        "   - Generalization ability\n",
        "3. Which batch size leads to the **noisiest gradient updates**?\n",
        "4. Which batch size generalizes better and why?"
      ],
      "metadata": {
        "id": "Wv6ZlRldHC09"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uBodrpTrHLMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Part 3: Overfitting and Regularization\n",
        "1. Train a large neural network (many parameters) on the dataset.\n",
        "2. Observe training vs. validation accuracy.  \n",
        "   - Do you see signs of overfitting?\n",
        "3. Apply regularization techniques:\n",
        "   - **L2 regularization**\n",
        "   - **Dropout**\n",
        "4. Compare the validation results before and after regularization.\n",
        "5. Which regularization method was more effective in reducing overfitting? Why?\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "9NDO_bUjHDz3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d74t2UPVHKdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Early Stopping\n",
        "1. Train the model for many epochs without early stopping.  \n",
        "   - Plot training, validation, and test curves.\n",
        "2. Train again with **early stopping** (monitor validation loss).\n",
        "3. Compare the number of epochs trained and the final validation/test accuracy.\n",
        "4. Explain how early stopping helps prevent overfitting.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "B0NQsxyYHFpy"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bnqrGbCzHI2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Reflection\n",
        "1. Summarize what you learned about:\n",
        "   - The role of optimizers\n",
        "   - The effect of batch size\n",
        "   - Regularization methods\n",
        "   - Early stopping\n",
        "   - Train/validation/test splits\n",
        "2. If you had to train a deep learning model on a new tabular dataset, what choices would you make for:\n",
        "   - Optimizer\n",
        "   - Batch size\n",
        "   - Regularization\n",
        "   - Early stopping\n",
        "   - Data splitting strategy  \n",
        "   and why?"
      ],
      "metadata": {
        "id": "Ix3ePqRnHHSs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zj8KFZ2LGsuQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}